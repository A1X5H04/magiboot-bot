# ==============================================================================
#
#  Modular Video Processing Workflow (Streamlined)
#
#  This workflow processes a video into a bootanimation in a single,
#  high-speed job to minimize GitHub Actions overhead.
#
# ==============================================================================

name: Process Video for Bootanimation

on:
  workflow_dispatch:
    inputs:
      video:
        description: 'FileID of a video to process'
        required: true
      other_metadata:
        description: '[JSON] Other metadata including {chatId, messageId, userId, title, creator}'
        required: false

env:
  BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
  STORAGE_PROVIDER_API_KEY: ${{ secrets.STORAGE_PROVIDER_API_KEY }}
  TELEGRAM_BOT_WEBHOOK_URL: ${{ secrets.TELEGRAM_BOT_WEBHOOK_URL }}

  INTERNAL_DEBUG_LOG: ${{ github.workspace }}/build_log.jsonl
  USER_ERROR_LOG: ${{ github.workspace }}/user_errors.log
  RUN_DEBUG_LOG: "false" # "true" for verbose logging

jobs:
  # =====================================================================================
  # JOB 1: BUILD & DEPLOY (MERGED)
  # - This single job handles setup, processing, packaging, and deployment.
  # =====================================================================================
  build_and_deploy:
    name: "Build & Deploy Module"
    runs-on: ubuntu-latest
    # outputs:
    #   msg_metadata: ${{ steps.publish_outputs.outputs.msg_metadata }}
    #   job_id: ${{ steps.publish_outputs.outputs.job_id }}
    #   stage_b64: ${{ steps.publish_outputs.outputs.stage_b64 }}
    #   error_json_array_b64: ${{ steps.publish_outputs.outputs.error_json_array_b64 }}
    #   error_plain_text_b64: ${{ steps.publish_outputs.outputs.error_plain_text_b64 }}
    env:
      CURRENT_STAGE: "Workflow Setup"
      JOB_ID: ${{ fromJson(inputs.other_metadata).jobId }}
      METADATA_JSON: ${{ inputs.other_metadata }}

    steps:
      # === SETUP STEPS ===
      - name: "Checkout repository"
        uses: actions/checkout@v4

      - name: "Install dependencies (jq, curl)"
        run: |
          source scripts/logger.sh
          log_info "Installing dependencies (jq, curl)..."
          sudo apt-get update -y >/dev/null 2>&1
          sudo apt-get install -y jq curl >/dev/null 2>&1
          log_info "Dependencies installed"

      - name: "Make scripts executable"
        run: chmod +x scripts/notify.sh scripts/logger.sh scripts/prepare_bootanimation.sh scripts/package_module.sh scripts/upload_file.sh

      - name: "Set Notification Metadata Env"
        run: |
          source scripts/logger.sh
          log_info "Setting MSG_METADATA_JSON environment variable..."
          # Use jq to extract the .msg_metadata object and output as compact JSON
          # This is the same as 'fromJson(...).msg_metadata | toJson'
          echo "MSG_METADATA_JSON=$(echo "$METADATA_JSON" | jq -c '.msg_metadata')" >> $GITHUB_ENV

      # - name: "Parse and validate metadata"
      #   id: parse_metadata
      #   # FIX: Pass complex JSON input via an environment variable
      #   # This prevents shell errors if the JSON contains single quotes.
      #   env:
      #     METADATA_JSON: ${{ inputs.other_metadata }}
      #   run: |
      #     source scripts/logger.sh
      #     log_info "Parsing workflow metadata..."
          
      #     if [ -z "$METADATA_JSON" ]; then
      #       log_fatal "Metadata JSON is empty. Workflow cannot proceed."
      #       exit 1
      #     fi

      #     PARSED_META=$(echo "$METADATA_JSON" | jq -c '{ "jobId": .jobId, "chatId": .msg_metadata.chatId, "messageId": .msg_metadata.messageId, "title": .title, "creator": .creator, "ref_message_id": .ref_message_id, "unique_file_id": .unique_file_id, "bootanim_config": .bootanim_config, "tags": .tags }')
      #     MSG_METADATA=$(echo "$METADATA_JSON" | jq -c '{ "chat_id": .msg_metadata.chatId, "message_id": .msg_metadata.messageId }')

      #     if [ -z "$PARSED_META" ] || [ -z "$MSG_METADATA" ] || [ "$PARSED_META" == "null" ] || [ "$MSG_METADATA" == "null" ]; then
      #       log_fatal "Failed to parse metadata JSON. Check input format."
      #       exit 1
      #     fi

      #     echo "json_string=${PARSED_META}" >> "$GITHUB_OUTPUT"
      #     echo "msg_metadata=${MSG_METADATA}" >> "$GITHUB_OUTPUT"
      #     log_info "Metadata parsed."

      - name: "Send 'Processing' status"
        run: |
          scripts/notify.sh --status "processing"

      - name: "Download video file"
        id: download
        run: |
          source scripts/logger.sh
          echo "CURRENT_STAGE=Video Download" >> $GITHUB_ENV
          set -e
          FILE_ID="${{ inputs.video }}"
          BOT_TOKEN="${{ env.BOT_TOKEN }}"
          log_info "Downloading video file (FileID: $FILE_ID)..."
          API_RESPONSE=$(curl -s "https://api.telegram.org/bot${BOT_TOKEN}/getFile?file_id=${FILE_ID}")
          if [[ "$(echo "$API_RESPONSE" | jq -r '.ok')" != "true" ]]; then
            log_fatal "Telegram API Error: $(echo "$API_RESPONSE" | jq -r '.description')"
          fi
          FILE_PATH=$(echo "$API_RESPONSE" | jq -r '.result.file_path')
          curl -s -L -o "video.mp4" "https://api.telegram.org/file/bot${BOT_TOKEN}/${FILE_PATH}"
          log_info "Video downloaded successfully to video.mp4"

      - name: "Cache FFmpeg Docker image"
        id: cache-ffmpeg
        uses: actions/cache@v4
        with:
          path: docker-image-cache
          key: ${{ runner.os }}-ffmpeg-4.4-ubuntu

      - name: "Load or Pull FFmpeg image"
        run: |
          source scripts/logger.sh
          mkdir -p docker-image-cache
          if [ -f docker-image-cache/ffmpeg.tar ]; then
            log_info "Loading FFmpeg from cache..."
            docker load -i docker-image-cache/ffmpeg.tar
            log_info "FFmpeg loaded."
          else
            echo "Pulling FFmpeg from registry..."
            log_info "Pulling FFmpeg from registry..."
            docker pull jrottenberg/ffmpeg:4.4-ubuntu
            docker save jrottenberg/ffmpeg:4.4-ubuntu -o docker-image-cache/ffmpeg.tar
            log_info "FFmpeg saved to cache."
          fi

      - name: "Run Processing Script"
        id: run_processing
        # FIX: Pass the parsed JSON string via env var to avoid quote injection
        env:
          METADATA_JSON_ENV: ${{ steps.parse_metadata.outputs.json_string }}
        run: |
          source scripts/logger.sh
          chmod +x scripts/prepare_bootanimation.sh scripts/notify.sh scripts/logger.sh
          log_info "Starting containerized video processing..."
          
          CONTAINER_USER_ERROR_LOG="/workdir/user_errors.log"
          CONTAINER_INTERNAL_DEBUG_LOG="/workdir/build_log.jsonl"

          CONTAINER_COMMAND="chmod +x scripts/logger.sh scripts/prepare_bootanimation.sh && apt-get update -y >/dev/null 2>&1 && apt-get install -y jq >/dev/null 2>&1 && source scripts/logger.sh && ./scripts/prepare_bootanimation.sh video.mp4"
          
          # Execute, capturing stdout to variable and stderr to file
          OUTPUT_STRING=$(docker run --rm -v "$(pwd):/workdir" -w /workdir \
            -e METADATA_JSON \
            -e "INTERNAL_DEBUG_LOG=${CONTAINER_INTERNAL_DEBUG_LOG}" \
            -e "USER_ERROR_LOG=${CONTAINER_USER_ERROR_LOG}" \
            -e RUN_DEBUG_LOGS \
            -e CURRENT_STAGE \
            --entrypoint "bash" jrottenberg/ffmpeg:4.4-ubuntu \
            -c "$CONTAINER_COMMAND")
          
          log_info "Video processing script finished."
          while IFS='=' read -r key value; do
            if [ -n "$key" ] && [ -n "$value" ]; then
              echo "$key=$value" >> "$GITHUB_OUTPUT"
              if [ "$key" == "boot_output_dir" ]; then
                # Ensure the one required for the next step is named correctly
                echo "boot_output_dir_path=$value" >> "$GITHUB_OUTPUT"
              fi
            fi
          done <<< "$OUTPUT_STRING"

      - name: "Package the flashable module"
        id: package_module
        run: |
          source scripts/logger.sh
          echo "CURRENT_STAGE=Module Packaging" >> $GITHUB_ENV

          chmod +x scripts/package_module.sh
          log_info "Packaging final module..."
          MODULE_NAME=$(echo "$METADATA_JSON" | jq -r '.title')
          MODULE_CREATOR=$(echo "$METADATA_JSON" | jq -r '.creator.name')
          FINAL_FILENAME=$(scripts/package_module.sh "${{ steps.run_processing.outputs.boot_output_dir_path }}" ./scripts/module_template --module-name "$MODULE_NAME" --module-creator "$MODULE_CREATOR")
          echo "filename=${FINAL_FILENAME}" >> "$GITHUB_OUTPUT"
          log_info "Module packaged: $FINAL_FILENAME"

      - name: "Generate and Upload MP4 Preview"
        id: upload_preview
        run: |
          source scripts/logger.sh
          set -e 

          log_info "Generating MP4 preview..."
          docker run --rm -v "$(pwd):/workdir" -w /workdir \
          jrottenberg/ffmpeg:4.4-ubuntu \
          -v error -hwaccel auto -i video.mp4 \
          -vf "fps=15,scale=320:-2,format=yuv420p" \
          -an -c:v libx264 -crf 28 -preset ultrafast \
          -movflags +faststart preview.mp4

          if [ ! -f "preview.mp4" ]; then
            log_fatal "FFmpeg failed to generate preview.mp4."
            exit 1 # FIX: Ensure workflow stops on fatal error
          fi

          log_info "Uploading preview to tmpfiles.org..."
          API_RESPONSE=$(curl --fail -s -F "file=@preview.mp4" https://tmpfiles.org/api/v1/upload)

          if ! echo "$API_RESPONSE" | jq -e . > /dev/null; then
              log_fatal "Failed to upload to tmpfiles.org or received non-JSON response. API Response: $API_RESPONSE"
              exit 1 # FIX: Ensure workflow stops on fatal error
          fi

          RAW_URL=$(echo "$API_RESPONSE" | jq -r '.data.url')

          if [ -z "$RAW_URL" ] || [ "$RAW_URL" == "null" ]; then
            log_fatal "Failed to upload preview to tmpfiles.org. API Response: $API_RESPONSE"
            exit 1 # FIX: Ensure workflow stops on fatal error
          fi

          PREVIEW_URL=$(echo "$RAW_URL" | sed -e 's|http://|https://|' -e 's|tmpfiles.org/|tmpfiles.org/dl/|')

          log_info "Preview URL: $PREVIEW_URL"
          echo "preview_url=${PREVIEW_URL}" >> "$GITHUB_OUTPUT"

      - name: "Upload module and get download link"
        id: upload
        run: |
          source scripts/logger.sh
          echo "CURRENT_STAGE=Module Upload" >> $GITHUB_ENV

          chmod +x scripts/upload_file.sh
          log_info "Uploading final module to storage provider..."
          DOWNLOAD_LINK=$(scripts/upload_file.sh "${{ steps.package_module.outputs.filename }}")
          echo "download_link=${DOWNLOAD_LINK}" >> "$GITHUB_OUTPUT"
          log_info "Module upload complete."
      
      - name: "Prepare final post metadata"
        id: post_data
        # FIX: Pass ALL dynamic inputs via environment variables
        # This prevents the "JToken" error by not nesting expressions
        # inside the jq command string.
        # env:  
        #   TELEGRAM_BOT_WEBHOOK_URL: ${{ secrets.TELEGRAM_BOT_WEBHOOK_URL }}
        #   INPUT_JOB_ID: ${{ fromJson(steps.parse_metadata.outputs.json_string).jobId }}
        #   INPUT_MSG_METADATA: ${{ steps.parse_metadata.outputs.msg_metadata }}
        #   BASE_META: ${{ steps.parse_metadata.outputs.json_string }}
        #   DOWNLOAD_URL: ${{ steps.upload.outputs.download_link }}
        #   PREVIEW_URL: ${{ steps.upload_preview.outputs.preview_url }}
        #   VIDEO_RES: ${{ steps.run_processing.outputs.boot_video_resolution }}
        #   BOOT_RES: ${{ steps.run_processing.outputs.boot_bootanimation_resolution }}
        #   BOOT_FPS: ${{ steps.run_processing.outputs.boot_video_fps }}
        #   BOOT_TYPE: ${{ steps.run_processing.outputs.boot_bootanimation_module_type }}
        #   DURATION: ${{ steps.run_processing.outputs.boot_video_duration }}
        #   VIDEO_ID: ${{ inputs.video }}
        run: |
          source scripts/logger.sh
          echo "CURRENT_STAGE=Prepare Final Post" >> $GITHUB_ENV
          
          # Read all the outputs from previous steps
          DOWNLOAD_URL="${{ steps.upload.outputs.download_link }}"
          PREVIEW_URL="${{ steps.upload_preview.outputs.preview_url }}"
          VIDEO_RES="${{ steps.run_processing.outputs.boot_video_resolution }}"
          BOOT_RES="${{ steps.run_processing.outputs.boot_bootanimation_resolution }}"
          BOOT_FPS="${{ steps.run_processing.outputs.boot_video_fps }}"
          BOOT_TYPE="${{ steps.run_processing.outputs.boot_bootanimation_module_type }}"
          DURATION="${{ steps.run_processing.outputs.boot_video_duration }}"
          VIDEO_ID="${{ inputs.video }}"

          log_info "Generating final post metadata..."
          # Now, the jq command safely reads from env vars.
          POST_METADATA=$(jq -n -c \
            --argjson base_meta "$METADATA_JSON" \
            --arg download_url "$DOWNLOAD_URL" \
            --arg preview_url "$PREVIEW_URL" \
            --arg video_res "$VIDEO_RES" \
            --arg boot_res "$BOOT_RES" \
            --arg boot_fps "$BOOT_FPS" \
            --arg boot_type "$BOOT_TYPE" \
            --arg duration "$DURATION" \
            --arg video_file_id "$VIDEO_ID" \
            '
              {
                "title": $base_meta.title,
                "creator": { "user_id": $base_meta.creator.id, "name": $base_meta.creator.name },
                "download_url": $download_url,
                "preview_url": $preview_url,
                "tags": $base_meta.tags,
                "video": { "file_id": $video_file_id, "file_unique_id": $base_meta.unique_file_id, "ref_message_id": $base_meta.ref_message_id },
                "details": {
                  "resolution": { "module": $boot_res, "video": $video_res },
                  "fps": ($boot_fps | tonumber),
                  "duration": ($duration | tonumber | round),
                  "type": $boot_type
                }
              }
          ')

          echo "post_metadata=$POST_METADATA" >> "$GITHUB_OUTPUT"
          log_info "Post metadata generated."

      - name: "Send 'Completed' status"
        if: success()
        run: |
          echo "CURRENT_STAGE=Completed" >> $GITHUB_ENV
          scripts/notify.sh --status "completed" \
                 --data "${{ steps.post_data.outputs.post_metadata }}"

      # This step will ONLY run if ANY preceding step failed
      - name: "Send 'Failed' status"
        if: failure()
        run: |
          scripts/notify.sh --status "failed" \
                 --message "Job failed at stage: $CURRENT_STAGE"